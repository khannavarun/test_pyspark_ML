{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Exemple\").config(\"spark.some.config.option\", \"some-value\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"iris.csv\", header=True, sep=\",\", inferSchema=True).toDF(\"sep_len\", \"sep_wid\", \"pet_len\", \"pet_wid\", \"variety\")\n",
    "df_temp = VectorAssembler( inputCols=[\"sep_len\", \"sep_wid\", \"pet_len\", \"pet_wid\"], outputCol=\"features\"  ).transform(df)\n",
    "df = df_temp.drop(\"sep_len\", \"sep_wid\", \"pet_len\", \"pet_wid\")\n",
    "df = StringIndexer( inputCol=\"variety\", outputCol=\"label\" ).fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- variety: string (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- label: double (nullable = false)\n",
      "\n",
      "None\n",
      "             0     1                   2       3          4\n",
      "summary  count  mean              stddev     min        max\n",
      "variety    150  None                None  Setosa  Virginica\n",
      "label      150   1.0  0.8192319205190407     0.0        2.0\n",
      "+-------+-----------------+-----+\n",
      "|variety|         features|label|\n",
      "+-------+-----------------+-----+\n",
      "| Setosa|[5.1,3.5,1.4,0.2]|  2.0|\n",
      "| Setosa|[4.9,3.0,1.4,0.2]|  2.0|\n",
      "| Setosa|[4.7,3.2,1.3,0.2]|  2.0|\n",
      "| Setosa|[4.6,3.1,1.5,0.2]|  2.0|\n",
      "| Setosa|[5.0,3.6,1.4,0.2]|  2.0|\n",
      "+-------+-----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print df.printSchema() # print datatype of each column under tree representation\n",
    "print df.describe().toPandas().transpose()\n",
    "print df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df.randomSplit( [0.7,0.3], seed = 11 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler( inputCol=\"features\", outputCol=\"scaledFeatures\" )\n",
    "rf = RandomForestClassifier( labelCol=\"label\", featuresCol=\"scaledFeatures\", numTrees=250, seed=42 )\n",
    "\n",
    "pipeline = Pipeline( stages=[scaler, rf] )\n",
    "\n",
    "paramGrid = ParamGridBuilder()\\\n",
    "  .addGrid(rf.maxDepth, [2, 3, 4])\\\n",
    "  .addGrid(rf.numTrees, [25, 50, 75])\\\n",
    "  .build()\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"f1\")\n",
    "cv = CrossValidator(estimator=pipeline, evaluator=evaluator, estimatorParamMaps=paramGrid, numFolds=5)\n",
    "cv = cv.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'numTrees': 25, 'maxDepth': 2} 0.927686480186\n",
      "{'numTrees': 50, 'maxDepth': 2} 0.93559793148\n",
      "{'numTrees': 75, 'maxDepth': 2} 0.93559793148\n",
      "{'numTrees': 25, 'maxDepth': 3} 0.93559793148\n",
      "{'numTrees': 50, 'maxDepth': 3} 0.943888529771\n",
      "{'numTrees': 75, 'maxDepth': 3} 0.953011336788\n",
      "{'numTrees': 25, 'maxDepth': 4} 0.953011336788\n",
      "{'numTrees': 50, 'maxDepth': 4} 0.934690668808\n",
      "{'numTrees': 75, 'maxDepth': 4} 0.953011336788\n"
     ]
    }
   ],
   "source": [
    "params = [{p.name: v for p, v in m.items()} for m in cv.getEstimatorParamMaps()]\n",
    "for ps, metric in zip(params, cv.avgMetrics):\n",
    "    print ps, metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model :\n",
      "{'numTrees': 75, 'maxDepth': 3}\n"
     ]
    }
   ],
   "source": [
    "java_model = cv.bestModel.stages[-1]._java_obj\n",
    "print \"Best Model :\" \n",
    "print {param.name: java_model.getOrDefault(java_model.getParam(param.name)) for param in paramGrid[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cv.bestModel.transform(test).select(\"prediction\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.0243902\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.975609756098\n",
      "Recall = 0.975609756098\n",
      "F1 Score = 0.975609756098\n"
     ]
    }
   ],
   "source": [
    "metrics = MulticlassMetrics(predictions.rdd)\n",
    "print(\"Precision = %s\" % metrics.precision())\n",
    "print(\"Recall = %s\" % metrics.recall())\n",
    "print(\"F1 Score = %s\" % metrics.fMeasure())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [(i.asDict().values())[0] for i in df.select(\"label\").distinct().collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0.0 P  = 1.0\n",
      "          R  = 0.928571428571\n",
      "          F1 = 0.962962962963\n",
      "Class 1.0 P  = 0.923076923077\n",
      "          R  = 1.0\n",
      "          F1 = 0.96\n",
      "Class 2.0 P  = 1.0\n",
      "          R  = 1.0\n",
      "          F1 = 1.0\n"
     ]
    }
   ],
   "source": [
    "for label in sorted(labels):\n",
    "    print\"Class %s\" % (label),  \"P  = %s\" % (metrics.precision(label))\n",
    "    print\"         \"          , \"R  = %s\" % (metrics.recall(label))\n",
    "    print\"         \"          , \"F1 = %s\" % (metrics.fMeasure(label, beta=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
